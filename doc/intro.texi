
@page
@node    Introduction
@chapter Introduction
@cindex  Introduction

What good are code complexity analyzers?  The purpose of these tools
is not to come up with a number wherein one value is good and another
value is bad.  There are a few primary purposes for these tools:

@enumerate
@item
To get a handle on the difficulty in understanding
a large collection of software.
@item
If you do not have a history of difficult (buggy) modules,
it is useful to know where problems are most likely to be hiding.
@item
A reminder to yourself that you see what you've written as obvious,
but others may not.  It is useful to have a hint about what code may
seem harder to understand by others.
@end enumerate

But why another complexity analyzer?  The McCabe tool exists.
I think the job it does is too rough.

@table @samp
@item code length
Since McCabe does not factor code length into its score, some folks
have taken to saying either long functions or a high McCabe score find
functions requiring attention.  But it means looking at two factors
without any visibility into how the length is obfuscating the code.

@item switch statement
@code{pmccabe} has changed the scoring of @code{switch}
statements because they seemed too high.  @code{switch} statements
are now ``free'' in the @file{pmccabe} analysis.  That's wrong, too.
The code length needs to be counted and the code within a @code{switch}
statement adds more to the difficulty of comprehension than code at
a shallower logic level.

@item logic conditions
McCabe does not score logic conditions very well.  It overcharges for
simple logical operations, it doesn't charge for comma operators, and
it undercharges for mixing assignment operators and relational operators
and the @code{and} and @code{or} logical operations.

For example:
@example
xx = (A && B) || (C && D) || (E && F);
@end example
scores as @code{6}.  Strictly speaking, there are, indeed, six code
paths there.  But that is not as complicated as this:
@example
  if (A) @{
    if (B) @{
      if (C) @{
        if (D)
          a-b-c-and-d;
      @} else if (E) @{
          a-b-no_c-and-e;
      @}
    @}
  @}
@end example
and yet this scores exactly the same.  @code{complexity} reduces the cost
to very little for a sequence of conditions at the same level.  (That
is, all @code{and} operators or all @code{or} operators.)  so the raw score
for these examples are 4 and 35, respectively (1 and 2 after scaling,
@pxref{complexity scale, --scale}).

If you nest boolean expressions, there is a little cost, assuming you
parenthesize grouped expressions so that @code{and} and @code{or}
operators do not appear at the same parenthesized level.  Also
assuming that you do not mix assignment and relational and boolean
operators all together.  If you do not parenthesize these into
subexpressions, their small scores get multiplied in ways that
sometimes wind up as a much higher score.

@item personal experience
I have used @code{pmccabe} on a number of occasions.  For a first
order approximation, it does okay.  However, I was interested in
zeroing in on the modules that needed the most help.  I was finding I
was looking at functions where I ought to have been looking at others.
So, I put this together to see if there was a better correlation
between what seemed like hard code to me and the score derived by an
analysis tool.

This has worked much better.  I ran @code{complexity} and
@code{pmccabe} against several million lines of code.  I correlated
the scores.  Where the two tools disagreed noticeably in relative
ranking, I took a closer look.  I found that @file{complexity} did,
indeed, seem to be more appropriate in its scoring.
@end table

Though I have tuned various knobs so that scores come out looking very
much like the ranges @code{pmccabe} turn out, @code{complexity} will
readily score as zero functions that are extremely simple, and code
that is very long or with many levels of logic nesting will wind up
scoring much higher than with @code{pmccabe}.

I have left the knobs available for tuning your results to your
own satisfaction.
