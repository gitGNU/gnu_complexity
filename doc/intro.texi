
@page
@node Introduction
@chapter Introduction
@cindex Introduction

What good are code complexity analyzers?  The purpose of these tools
is not to come up with a number wherein one value is good and another
value is bad.  There are a few primary purposes for these tools:

@enumerate
@item
To get a handle on the difficulty in understanding
a large collection of software.
@item
If you do not have a history of difficult (buggy) modules,
it is useful to know where problems are most likely to be hiding.
@item
A reminder to yourself that you see what you've written as obvious,
but others may not.  It is useful to have a hint about what code may
seem harder to understand by others.
@end enumerate

But why another complexity analyzer?  The McCabe tool exists.
I think the job it does is too rough.

@table @samp
@item code length
Since McCabe does not factor code length into its score, some folks
have taken to saying either long functions or a high McCabe score find
functions requiring attention.  But it means looking at two factors
without any visibility into how the length is obfuscating the code.

@item switch statement
@code{pmccabe} has changed the scoring of @code{switch}
statements because they seemed too high.  @code{switch} statements
are now ``free'' in the @file{pmccabe} analysis.  That's wrong, too.
The code length needs to be counted and the code within a @code{switch}
statement adds more to the difficulty of comprehension than code at
a shallower logic level.

@item logic conditions
McCabe does not score logic conditions very well.  It overcharges for
simple logical operations, it doesn't charge for comma operators, and
it undercharges for mixing assignment operators and relational operators
and the @code{and} and @code{or} logical operations.

For example:
@example
if (A && B) || (C && D) || (E && F) xx;
@end example
scores as @code{6}.  Strictly speaking, there are, indeed, six code
paths there.  But that is not as complicated as this:
@example
  if (A) @{
      if (B)
          a-and-b;
  @} else if (C) @{
      if (D)
          c-and-d;
  @} else if (E) @{
      if (F)
          e-and-f;
  @}
@end example
and yet they are scored the same.  @code{complexity} reduces the cost
to very little for a sequence of conditions at the same level.  (That
is, all @code{and} operators or all @code{or} operators.)  If you nest
boolean expressions, there is a little cost, assuming you parenthesize
grouped expressions so that @code{and} and @code{or} operators do not
appear at the same parenthesized level.  Also assuming that you do not
mix assignment and relational and boolean operators all together.  If
you do not parenthesize these into subexpressions, their small scores
get multiplied in ways that sometimes wind up as a much higher score.

@item personal experience
I have used @code{pmccabe} on a number of occasions.  For a first
order approximation, it does okay.  However, I was interested in
zeroing in on the modules that needed the most help.  I was finding I
was looking at functions where I ought to have been looking at others.
So, I put this together to see if there was a better correlation
between what seemed like hard code to me and the score derived by an
analysis tool.

This has worked much better.  I ran @code{complexity} and
@code{pmccabe} against several million lines of code.  I correlated
the scores.  Where the two tools disagreed noticeably in relative
ranking, I took a closer look.  I found that @file{complexity} did,
indeed, seem to be more appropriate in its scoring.
@end table

Though I have tuned various knobs so that scores come out looking very
much like the ranges @code{pmccabe} turn out, @code{complexity} will
readily score as zero functions that are extremely simple, and code
that is very long or with many levels of logic nesting will wind up
scoring much higher than with @code{pmccabe}.

I have left the knobs available for tuning your results to your
own satisfaction.

@page
@node    Complexity Computation
@chapter Complexity Computation
@cindex  Complexity Computation

Fundamentally, this program counts lines of non-comment source lines,
multiplies by a ``nesting factor'' for each level of logic nesting and
divides by a scaling factor so that the typical results lie roughly in
the same range as McCabe results.  That happens to be approximately 20.

@menu
* scores::      Complexity Scores
* stats::       Complexity Statistics
* tuning::      Scoring Adjustments
@end menu

@node     scores
@section  Complexity Scores
@cindex   scores

The ``Complexity Scores'' table shows the score of each procedure identified
that also exceeded the threshold score,
@xref{complexity threshold, ---threshold}.  The entries on each line are:

@itemize  @bullet
@item
The computed score
@item
The number of lines between the opening and closing curly braces
@item
The number of non-comment, non-blank lines found there
@item
The name of the source file
@item
The line number of the opening curly brace
@item
The name of the procedure
@end itemize

The output is sorted by the score and then the number of non-comment lines.
Procedures with scores below the threshold are not displayed.

@node     stats
@section  Complexity Statistics
@cindex   statistics

The statistics are displayed both as a table and as a histogram,
@xref{Example Output}.  It is under the control of the
@code{--histogram} option.  The statistics are for each non-comment
source line and each source line is given the score of its
encompassing procedure.  This way, larger procedures are given
proportionally more weight than one line procedures.

The histogram is broken up into three ranges.  Scores of 0 through 99
are displayed in 10 point groupings, 100 through 999 in 100 point
groupings and 1000 and above (good grief!!, but they exist) are in
1000 point groupings.  The number of asterisks represent the number
of lines of code that are in procedures that score in the specified
range.

The tabular statistics are also based on lines, not procedures.
@table @samp
@item Average line score
This is the procedure score times the non-comment
line count, all added up and divided by the total non-comment source
lines found.
@item Median line score
This score is found by adding the line counts in
the sorted complexity score table until the half-of-all-lines point is
reached.  The score for that procedure is the median score.  The
majority of procedures will have a smaller score, but those are
generally smaller procedures so they do not have as much weight.
@item Standard deviation
This is again based on each line being given the score of its
containing procedure.  It is the square root of the mean square of the
differences between individual line scores and the average line score.
@end table

@node     tuning
@section  Scoring Adjustments
@cindex   tuning
@cindex   scores

Scores can be adjusted with three different options:
@table @samp
@item nesting-penalty
@xref{complexity nesting-penalty, ---nesting-penalty}.
@item demi-nesting-penalty
@xref{complexity demi-nesting-penalty, ---demi-nesting-penalty}.
@item scale
@xref{complexity scale, ---scale}.
@end table

The raw score is the number of lines or statements, whichever is
greater, adjusted by a factor for the depth of the logic.  Statements
are nested when they are inside of a block of statements for a
``block'' statement (viz., ``do'', ``for'', ``if'', ``switch'' or
``while'').  Statements within blocks used to constrain the scope of
variables (not controlled by a block statement) are not multiplied by
this factor.

Expressions are nested when contained within parentheses.
The @i{cost} of these is different.  Block level nesting multiplies the
score for the block by the @code{--nesting-penalty} factor (2.0 by default).
Nested expressions are multiplied by the @code{--demi-nesting-penalty},
the square root of @code{--nesting-penalty} by default.

Some attempt is made to judge the complexity of an expression.
A complicated expression is one that contains an assignment operator,
more than one relation operator, or a mixture of ``and'' and ``or''
operators with any other different kind of non-arithmetic operator.
Expression scores are minimized by:

@itemize  @bullet
@item
Doing assignments outside of
boolean expressions, or at least parenthesizing them.
@item
Parenthesizing each relationship operation in an expression
of multiple ``and'' and/or ``or'' operations.  Yes, precedence
parses them correctly, but it is less clear.
@item
Parenthesizing groups of ``and'' and ``or'' operations so that
operators of only one type appear at one level.  For example,
the first expression below instead of the second.  Yes, precedence
means the effect is the same, but we're after code clarity so that
correctness is more obvious.
@example
1: ((a && b) || (c && d))
2: (a && b || c && d)
@end example
The first adds 2 to the raw score (before dividing by the scaling factor).
The latter will add 5, assuming a @code{demi-nesting-penalty} of @code{1.41}.
@end itemize
